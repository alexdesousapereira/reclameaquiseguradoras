---
title: "Análise de Dados das Empresas de Seguro"
author: "Alex de Sousa Pereira"
date: "24/10/2021"
output:
  rmarkdown::html_document:
  theme: lumen
---

(esse material complementar foi 100% produzido usando a linguagem R)

# Analisando os dados, criando gráficos e análise de texto com a linguagem R 

OBJETIVO

  - COMPARAR OS RESULTADOS DAS EMPRESAS

  - AVALIAR PONTOS FORTES E PONTOS FRACOS DE CADA EMPRESA

  - AVALIAR POSSÍVEL RELAÇÃO ENTRE AS PALAVRAS USADAS PELO CLIENTE NA RECLAMAÇÃO E A SOLUÇÃO (OU NÃO) DO CASO

### 1 - LEITURA DOS CONJUNTOS DE DADOS OBTIDOS POR WEBSCRAPING:

Bibliotecas que iremos utilizar:


```{r,message=FALSE,warning=F}
library(pacman)
```

```{r,message=FALSE,warning=F}
pacman::p_load(wordcloud2) # mineração de texto
pacman::p_load(tidytext) # mineração de texto
pacman::p_load(tm) # mineração de texto
pacman::p_load(tidyverse)  # tratamento de dados
pacman::p_load(plyr) # tratamento de dados
pacman::p_load(magrittr) # tratamento de dados
pacman::p_load(dplyr) # tratamento de dados
pacman::p_load(widyr)
pacman::p_load(igraph)
pacman::p_load(ggraph)
```

Carregando dados que iremos utilizar:

```{r,message=FALSE,warning=F}
info_reclamacoes_avaliadas <- read.csv('dados/DadosReclameAqui.csv',sep=',', encoding = 'UTF-8', stringsAsFactors = FALSE)
```

Estrutura dos dados ```info_reclamacoes_avaliadas```:

```{r,message=FALSE,warning=F}
str(info_reclamacoes_avaliadas)
head(info_reclamacoes_avaliadas)
```


### 2 - MINERAÇÃO DE TEXTO - ANÁLISE DAS RECLAMAÇÕES

Texto ocultado pelo Reclame Aqui:

Algumas reclamações tem o texto “[Editado pelo Reclame Aqui]” quando o texto original viola as regras do site e precisa ser ocultado.

```{r,message=FALSE,warning=F}
info_reclamacoes_avaliadas$titulo<-
  gsub('Editado pelo Reclame Aqui','editado_RA',info_reclamacoes_avaliadas$titulo)
```

Criar uma linha para cada palavra do título:

```{r,message=FALSE,warning=F}
avaliadas_token<-info_reclamacoes_avaliadas %>% 
  select(titulo,row_hash) %>% 
  unnest_tokens(word,titulo) 
```

Stopwords são palavras neutras, que não nos ajudam em nada para analisar a reclamação do consumidor. São por exemplo as preposições.

A função ```stopwords``` nos retorna vários exemplos de stopwords.

Remover stopwords:

```{r,message=FALSE,warning=F}
stop_words_pt<-data.frame(word=(stopwords(kind = "pt")))
avaliadas_token <- avaliadas_token %>% 
  anti_join(stop_words_pt)
```
Remover palavras com duas letras, pois provavelmente também serão palavras inúteis:

```{r,message=FALSE,warning=F}
avaliadas_token %<>% 
  filter(sapply(avaliadas_token$word,nchar)>2)
```


#### HÁ RELAÇÃO ENTRE AS PALAVRAS DO TÍTULO E A SOLUÇÃO DA RECLAMAÇÃO?

O que queremos saber aqui é se a chance da empresa solucionar o problema está relacionada às palavras escritas no título da reclamação.


```{r,message=FALSE,warning=F}
#juntar o status da reclamação no conjunto de dados com as palavras

avaliadas_token <-join(avaliadas_token,
info_reclamacoes_avaliadas[,c("row_hash","sentimento")])

analise_palavras<-avaliadas_token %>%
  group_by(word) %>%
  dplyr::mutate(percentual_solucao = sum(sentimento=="positivo")/dplyr::n(),
         qnt_palavra = dplyr::n()) %>%
  select(word,percentual_solucao,qnt_palavra) %>%
  unique()%>%
  ungroup()

#filtrar apenas os resultados com frequencia maior que 15
analise_palavras %<>% filter(qnt_palavra >15)
```

E se a gente separar por empresa?

```{r,message=FALSE,warning=F}
avaliadas_token_empresa <- join(avaliadas_token,
info_reclamacoes_avaliadas[,c("row_hash","empresa")])
```

Percentual geral de solução por empresa sem considerar as palavras do título

```{r,message=FALSE,warning=F}
analise_empresas <-avaliadas_token_empresa %>%
  group_by(empresa) %>%
  dplyr::mutate(percentual_solucao = sum(sentimento=="negativo")/n()) %>%
  select(percentual_solucao,empresa) %>%
  unique() %>%
  ungroup()
```

Percentual geral de solução por empresa por palavras no título

```{r,message=FALSE,warning=F}
analise_palavras_empresas <-avaliadas_token_empresa %>%
  group_by(word,empresa) %>%
  dplyr::mutate(percentual_solucao = sum(sentimento=="positivo")/n(),
         qnt_palavra = n()) %>%
  select(word,percentual_solucao,qnt_palavra,empresa) %>%
  unique()%>%
  ungroup()
analise_palavras_empresas %<>% filter(qnt_palavra >10)
```


#### CORRELAÇÃO ENTRE PALAVRAS:

QUAIS AS PALAVRAS QUE MAIS APARECERAM JUNTAS?

```{r,message=FALSE,warning=F}
correlacao <- avaliadas_token %>%
  group_by(word) %>% 
  filter(n() > 10) %>%
  pairwise_cor(word, row_hash, sort = TRUE,upper=F)%>%
  ungroup()
correlacao %<>% filter(correlation >0.3)
correlacao %>%
  arrange(-correlation) %>%
  top_n(10) %>% #Filtrar as 10 maiores
  graph_from_data_frame() %>%
  ggraph(layout = 'fr') + 
  guides(edge_alpha = "none", edge_width = "none") +
  scale_edge_colour_gradientn(limits = c(-1, 1), colors = c("firebrick2", "dodgerblue2")) +
  geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) + 
  geom_node_point(color = 'lightblue', size = 5) + 
  geom_node_text(aes(label = name), repel = TRUE) + 
  theme_graph() +
  labs(title = "Palavras que geralmente apareceram juntas em reclamações de Seguro")
```

#### Palavras que mais aparecem:

```{r,message=FALSE,warning=F}
dados_grafico<- avaliadas_token %>% dplyr::count(word, sort = TRUE)  %>% top_n(5) %>%
   mutate(word = reorder(word,n))

  ggplot(dados_grafico,aes(x = word, y=n)) + 
  geom_col() +
  xlab(NULL) +
  coord_flip() +
  theme_classic() +
  labs(x = "",
       y = "Qnt. aparições",
       title = paste0("Palavras que aparecem nas reclamações"))
```

#### NUVEM DE PALAVRAS

Esse é o gráfico 'wordcloud'

```{r,message=FALSE,warning=F}
library(wordcloud2)
  wordcloud_dados <- analise_palavras %>% 
    select(word,qnt_palavra) %>%
     dplyr::rename(freq = qnt_palavra)
  
  wordcloud2(data = wordcloud_dados)
```
### Sentimento das palavras
  Nesta etapa, será atribuído uma análise de sentimento aos dados por meio do score das palavras.

```{r,message=FALSE,warning=F}

sentimentos<-avaliadas_token %>% group_by(word,sentimento) %>% 
    dplyr::count(word, sort = TRUE)

  sentimentos %<>% select(word,sentimento,n)  

  sentimentos %>%  group_by(sentimento) %>%
    top_n(5) %>%
    ungroup() %>%
    mutate(word = reorder(word,n)) %>%
    ggplot(aes(word,n,fill=sentimento))+
    geom_col(show.legend = FALSE) +
    facet_wrap(~sentimento,scales ="free_y") +
    labs(title= paste0("Palavras relacionadas a busca: "),
         y = "Qnt. vezes que usaram a palavra",
         x = NULL) +
    coord_flip() + theme_bw()
```


### 5 Repositório no Github

Todos os arquivos utilizados no desenvolvimento desta análise ficaram disponíveis no meu Github.

[Para acessar, clique aqui.](https://github.com/alexdesousapereira){target="_blank"}

